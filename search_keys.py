import os
import requests
import time
import random
from datetime import datetime

# --- é…ç½®åŒº ---

# ä»ç¯å¢ƒå˜é‡ä¸­è·å– GitHub ä¸ªäººè®¿é—®ä»¤ç‰Œ (PAT)
# GitHub Actions ä¼šè‡ªåŠ¨æä¾›è¿™ä¸ªç¯å¢ƒå˜é‡ï¼Œç¡®ä¿äº†å®‰å…¨æ€§
GITHUB_TOKEN = os.getenv('GH_PAT')
if not GITHUB_TOKEN:
    raise ValueError("æœªæ‰¾åˆ° GitHub PATã€‚è¯·è®¾ç½® 'GH_PAT' ç¯å¢ƒå˜é‡ã€‚")

# è¦æœç´¢çš„å­—ç¬¦ä¸²å‰ç¼€ã€‚ä½ å¯ä»¥æ ¹æ®éœ€è¦æ·»åŠ æ›´å¤š
SEARCH_QUERIES = [
    'AIzaSy'
]

# ä¿å­˜ç»“æœçš„æ–‡ä»¶å
OUTPUT_FILE = "api.txt"

# GitHub API è¯·æ±‚å¤´ï¼ŒåŒ…å«è®¤è¯ä¿¡æ¯
HEADERS = {
    'Authorization': f'token {GITHUB_TOKEN}',
    'Accept': 'application/vnd.github.v3.text-match+json'
}

# --- åŠŸèƒ½å‡½æ•° ---

def check_rate_limit():
    """æ£€æŸ¥GitHub APIçš„é€Ÿç‡é™åˆ¶ï¼Œå¦‚æœæ¥è¿‘é™åˆ¶åˆ™æš‚åœç­‰å¾…ã€‚"""
    try:
        response = requests.get('https://api.github.com/rate_limit', headers=HEADERS)
        response.raise_for_status()
        rate_info = response.json().get('resources', {}).get('search', {})
        remaining = rate_info.get('remaining', 0)
        reset_time = rate_info.get('reset', 0)
        
        print(f"APIé€Ÿç‡é™åˆ¶: å‰©ä½™ {remaining} æ¬¡è¯·æ±‚ã€‚é‡ç½®æ—¶é—´: {datetime.fromtimestamp(reset_time).strftime('%Y-%m-%d %H:%M:%S')}")
        
        # å¦‚æœå‰©ä½™è¯·æ±‚æ¬¡æ•°å°äº5ï¼Œå°±æš‚åœç›´åˆ°é‡ç½®æ—¶é—´
        if remaining < 5:
            sleep_time = max(0, reset_time - time.time()) + 5 # å¢åŠ 5ç§’ç¼“å†²
            print(f"é€Ÿç‡é™åˆ¶è¿‡ä½ï¼Œç¨‹åºå°†æš‚åœ {sleep_time:.2f} ç§’ã€‚")
            time.sleep(sleep_time)
            
    except requests.exceptions.RequestException as e:
        print(f"æ£€æŸ¥é€Ÿç‡é™åˆ¶æ—¶å‡ºé”™: {e}")
        # å‡ºé”™æ—¶ï¼Œé»˜è®¤æš‚åœ60ç§’ä»¥ä¿è¯å®‰å…¨
        time.sleep(60)

def search_github(query):
    """æ ¹æ®ç»™å®šçš„æŸ¥è¯¢å­—ç¬¦ä¸²åœ¨ GitHub ä¸Šæœç´¢ä»£ç ã€‚"""
    found_keys = set()
    base_url = 'https://api.github.com/search/code'
    
    # æ„é€ æ›´ç²¾ç¡®çš„æŸ¥è¯¢ï¼ŒåªæŸ¥æ‰¾æ—§ä»£ç ï¼Œä»¥è¿‡æ»¤æ‰å¤§é‡æµ‹è¯•å’Œç¤ºä¾‹Key
    # full_query = f'{query} pushed:<{datetime.now().year}-01-01'
    full_query = query # ä¸ºäº†æœ€å¤§åŒ–æœç´¢ç»“æœï¼Œæˆ‘ä»¬å…ˆç”¨ç®€å•æŸ¥è¯¢
    
    params = {
        'q': full_query,
        'per_page': 100, # æ¯é¡µæœ€å¤š100ä¸ªç»“æœ
        'page': 1
    }
    
    print(f"ğŸš€ å¼€å§‹æœç´¢: '{full_query}'")
    
    while True:
        check_rate_limit() # æ¯æ¬¡è¯·æ±‚å‰éƒ½æ£€æŸ¥é€Ÿç‡é™åˆ¶
        try:
            response = requests.get(base_url, headers=HEADERS, params=params)
            response.raise_for_status()
            data = response.json()
        except requests.exceptions.HTTPError as e:
            # GitHub APIå¯¹è¿‡äºå¤æ‚çš„æœç´¢ä¼šè¿”å›422ï¼Œæ­¤æ—¶é€šå¸¸æ„å‘³ç€æœç´¢ç»“æŸ
            if e.response.status_code == 422:
                print("å·²è¾¾åˆ°æ­¤æŸ¥è¯¢çš„å¯æœç´¢ç»“æœæœ«å°¾ã€‚")
                break
            print(f"HTTPè¯·æ±‚é”™è¯¯: {e}")
            time.sleep(60)
            continue
        except requests.exceptions.RequestException as e:
            print(f"ç½‘ç»œè¯·æ±‚é”™è¯¯: {e}")
            time.sleep(60)
            continue
            
        items = data.get('items', [])
        
        # å¦‚æœå½“å‰é¡µæ²¡æœ‰ç»“æœï¼Œè¯´æ˜æœç´¢ç»“æŸ
        if not items:
            print("å½“å‰é¡µæ— ç»“æœï¼Œç»“æŸæœç´¢ã€‚")
            break

        for item in items:
            repo_name = item.get('repository', {}).get('full_name', 'æœªçŸ¥ä»“åº“')
            file_path = item.get('path', 'æœªçŸ¥è·¯å¾„')
            
            # ä»è¿”å›çš„æ–‡æœ¬åŒ¹é…ä¸­æå–å«æœ‰Keyçš„æ•´è¡Œå†…å®¹
            for match in item.get('text_matches', []):
                line_content = match.get('fragment', '')
                
                # ç®€å•æå–é€»è¾‘ï¼šåˆ†å‰²è¡Œå†…å®¹ï¼Œæ‰¾åˆ°ä»¥æŸ¥è¯¢å¼€å¤´çš„å•è¯
                words = line_content.split()
                for word in words:
                    # æ¸…ç†å•è¯å‘¨å›´å¯èƒ½å­˜åœ¨çš„å¼•å·ã€åˆ†å·ç­‰å­—ç¬¦
                    cleaned_word = word.strip('\'",;()[]{}<>') 
                    if cleaned_word.startswith(query) and len(cleaned_word) > len(query): # ç¡®ä¿ä¸æ˜¯åªæœ‰å‰ç¼€
                        print(f"  [+] å‘ç°æ½œåœ¨Key: {cleaned_word} | æ¥æº: {repo_name}/{file_path}")
                        
                        # --- ä¸»è¦ä¿®æ”¹ç‚¹åœ¨è¿™é‡Œ ---
                        # ç›´æ¥å°†æ¸…ç†åçš„å•è¯ï¼ˆå³API Keyï¼‰æ·»åŠ åˆ°é›†åˆä¸­
                        found_keys.add(cleaned_word)
                        # -----------------------

        # ç¿»é¡µé€»è¾‘ï¼šæ£€æŸ¥å“åº”å¤´ä¸­æ˜¯å¦æœ‰ 'next' é“¾æ¥
        if 'next' in response.links:
            params['page'] += 1
            time.sleep(random.uniform(2, 5)) # éšæœºæš‚åœ2-5ç§’ï¼Œé¿å…è¯·æ±‚è¿‡äºé¢‘ç¹
        else:
            print(f"âœ… æŸ¥è¯¢ '{query}' ç»“æŸã€‚")
            break
            
    return found_keys

def main():
    """ä¸»å‡½æ•°ï¼Œè´Ÿè´£æ•´ä¸ªæµç¨‹çš„è°ƒåº¦ã€‚"""
    all_found_keys = set()

    # è¯»å– api.txt ä¸­å·²æœ‰çš„Keyï¼Œé¿å…é‡å¤æ·»åŠ 
    if os.path.exists(OUTPUT_FILE):
        with open(OUTPUT_FILE, 'r', encoding='utf-8') as f:
            for line in f:
                all_found_keys.add(line.strip())
        print(f"å·²ä» {OUTPUT_FILE} åŠ è½½ {len(all_found_keys)} æ¡å·²æœ‰è®°å½•ã€‚")

    # éå†æ‰€æœ‰æŸ¥è¯¢æ¡ä»¶
    for query in SEARCH_QUERIES:
        keys_from_query = search_github(query)
        all_found_keys.update(keys_from_query)
    
    print(f"\næœç´¢å®Œæˆã€‚å…±è®¡ {len(all_found_keys)} æ¡ä¸é‡å¤è®°å½•ï¼Œå°†å†™å…¥ {OUTPUT_FILE}...")

    # å°†æ‰€æœ‰ä¸é‡å¤çš„Keyæ’åºåå†™å…¥æ–‡ä»¶
    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
        # æŒ‰å­—æ¯é¡ºåºæ’åºåå†™å…¥æ–‡ä»¶
        for key in sorted(list(all_found_keys)):
            f.write(f"{key}\n")
    
    print("âœ¨ ä»»åŠ¡å®Œæˆï¼")

if __name__ == '__main__':
    main()
