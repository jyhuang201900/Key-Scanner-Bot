import os
import requests
import time
import random
from datetime import datetime, timedelta
from tqdm import tqdm # âœ¨ å¼•å…¥tqdmåº“ï¼Œç”¨äºæ˜¾ç¤ºæ€»ä½“è¿›åº¦

# --- é…ç½®åŒº (ä¿æŒä¸å˜) ---
GITHUB_TOKEN = os.getenv('GH_PAT')
if not GITHUB_TOKEN:
    raise ValueError("æœªæ‰¾åˆ° GitHub PATã€‚è¯·è®¾ç½® 'GH_PAT' ç¯å¢ƒå˜é‡ã€‚")

BASE_SEARCH_PREFIX = 'AIzaSy'
OUTPUT_FILE = "api.txt"
HEADERS = {
    'Authorization': f'token {GITHUB_TOKEN}',
    'Accept': 'application/vnd.github.v3.text-match+json'
}

# --- åŠŸèƒ½å‡½æ•° (check_rate_limit, search_github, generate_search_queries å‡ä¿æŒä¸å˜) ---
def check_rate_limit():
    """æ£€æŸ¥GitHub APIçš„é€Ÿç‡é™åˆ¶ï¼Œå¦‚æœæ¥è¿‘é™åˆ¶åˆ™æš‚åœç­‰å¾…ã€‚"""
    try:
        response = requests.get('https://api.github.com/rate_limit', headers=HEADERS)
        response.raise_for_status()
        rate_info = response.json().get('resources', {}).get('search', {})
        remaining = rate_info.get('remaining', 0)
        reset_time = rate_info.get('reset', 0)
        
        # å‡å°‘ä¸å¿…è¦çš„æ‰“å°ï¼Œåªåœ¨æ¥è¿‘é™åˆ¶æ—¶æç¤º
        if remaining < 10:
            print(f"APIé€Ÿç‡é™åˆ¶: å‰©ä½™ {remaining} æ¬¡è¯·æ±‚ã€‚é‡ç½®æ—¶é—´: {datetime.fromtimestamp(reset_time).strftime('%Y-%m-%d %H:%M:%S')}")
        
        if remaining < 5:
            sleep_time = max(0, reset_time - time.time()) + 5
            print(f"é€Ÿç‡é™åˆ¶è¿‡ä½ï¼Œç¨‹åºå°†æš‚åœ {sleep_time:.2f} ç§’ã€‚")
            time.sleep(sleep_time)
            
    except requests.exceptions.RequestException as e:
        print(f"æ£€æŸ¥é€Ÿç‡é™åˆ¶æ—¶å‡ºé”™: {e}")
        time.sleep(60)

def search_github(query, existing_keys):
    """
    æ ¹æ®å•ä¸ªç²¾ç¡®çš„æŸ¥è¯¢åœ¨ GitHub ä¸Šæœç´¢ä»£ç ã€‚
    è¿”å›ä¸€ä¸ªåŒ…å«æ–°å‘ç°çš„Keyçš„é›†åˆã€‚
    """
    found_keys = set()
    base_url = 'https://api.github.com/search/code'
    params = {'q': query, 'per_page': 100, 'page': 1}
    
    # print(f"ğŸš€ å¼€å§‹æœç´¢: '{query}'") # åœ¨ä¸»å¾ªç¯ä¸­æ‰“å°ï¼Œå‡å°‘å†—ä½™ä¿¡æ¯
    
    try:
        while True:
            check_rate_limit()
            response = requests.get(base_url, headers=HEADERS, params=params)
            
            if response.status_code == 403 and 'abuse detection' in response.text.lower():
                print("ğŸš¨ è§¦å‘æ»¥ç”¨æ£€æµ‹æœºåˆ¶ï¼Œæš‚åœ5åˆ†é’Ÿ...")
                time.sleep(300)
                continue

            response.raise_for_status()
            data = response.json()
            
            items = data.get('items', [])
            if not items:
                break

            for item in items:
                for match in item.get('text_matches', []):
                    line_content = match.get('fragment', '')
                    words = line_content.replace(':', ' ').replace('=', ' ').split()
                    for word in words:
                        cleaned_word = word.strip('\'",;()[]{}<>`').rstrip('.')
                        if cleaned_word.startswith(BASE_SEARCH_PREFIX) and len(cleaned_word) >= 39:
                            if cleaned_word not in existing_keys and cleaned_word not in found_keys:
                                repo_name = item.get('repository', {}).get('full_name', 'æœªçŸ¥')
                                print(f"  [+] å‘ç°æ–°Key: {cleaned_word} (æ¥è‡ª: {repo_name})")
                                found_keys.add(cleaned_word)

            if 'next' in response.links:
                params['page'] += 1
                time.sleep(random.uniform(3, 6))
            else:
                break
                
    except requests.exceptions.HTTPError as e:
        if e.response.status_code == 422:
            pass
        else:
            print(f"HTTPè¯·æ±‚é”™è¯¯: {e}")
            time.sleep(60)
    except requests.exceptions.RequestException as e:
        print(f"ç½‘ç»œè¯·æ±‚é”™è¯¯: {e}")
        time.sleep(60)
            
    return found_keys

def generate_search_queries():
    """
    ç”Ÿæˆä¸€ç³»åˆ—ç²¾ç»†åŒ–çš„æœç´¢æŸ¥è¯¢æ¥ç»•è¿‡1000ä¸ªç»“æœçš„é™åˆ¶ã€‚
    """
    queries = []
    current_year = datetime.now().year
    for year in range(current_year, 2014, -1):
        for month in range(1, 13):
            start_date = f"{year}-{month:02d}-01"
            end_date_dt = (datetime.strptime(start_date, "%Y-%m-%d") + timedelta(days=32)).replace(day=1) - timedelta(days=1)
            end_date = end_date_dt.strftime("%Y-%m-%d")
            queries.append(f'"{BASE_SEARCH_PREFIX}" created:{start_date}..{end_date}')

    characters = 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789-_'
    for char1 in characters:
        queries.append(f'"{BASE_SEARCH_PREFIX}{char1}"')
    
    print(f"ğŸ‰ å·²ç”Ÿæˆ {len(queries)} ä¸ªç²¾ç»†åŒ–æœç´¢æŸ¥è¯¢ã€‚")
    return queries


# --- âœ¨ ä¸»å‡½æ•° (æ ¸å¿ƒä¿®æ”¹åŒº) ---
def main():
    """ä¸»å‡½æ•°ï¼Œè´Ÿè´£æ•´ä¸ªæµç¨‹çš„è°ƒåº¦ã€‚"""
    
    # æ­¥éª¤ 1: è¯»å–æ‰€æœ‰å·²å­˜åœ¨çš„keyåˆ°å†…å­˜ä¸­çš„é›†åˆï¼Œç”¨äºå»é‡æ£€æŸ¥
    all_found_keys = set()
    if os.path.exists(OUTPUT_FILE):
        with open(OUTPUT_FILE, 'r', encoding='utf-8') as f:
            # å…¼å®¹æ—§çš„æ–‡ä»¶æ ¼å¼ï¼Œå³ä½¿æœ‰'|'ä¹Ÿèƒ½æ­£ç¡®è¯»å–
            all_found_keys = {line.split('|')[0].strip() for line in f if line.strip()}
        print(f"âœ… å·²ä» {OUTPUT_FILE} åŠ è½½ {len(all_found_keys)} æ¡å·²æœ‰è®°å½•ã€‚")
    else:
        print(f"ğŸ“‹ æœªæ‰¾åˆ° {OUTPUT_FILE}ï¼Œå°†åˆ›å»ºä¸€ä¸ªæ–°æ–‡ä»¶ã€‚")

    # æ­¥éª¤ 2: ç”Ÿæˆæ‰€æœ‰è¦æ‰§è¡Œçš„æœç´¢æŸ¥è¯¢
    queries_to_run = generate_search_queries()
    
    # æ­¥éª¤ 3: éå†æ‰§è¡Œæ‰€æœ‰æŸ¥è¯¢ï¼Œå¹¶ä½¿ç”¨tqdmæ˜¾ç¤ºæ€»ä½“è¿›åº¦
    total_new_keys_this_run = 0
    
    # ä½¿ç”¨tqdmæ¥åŒ…è£…æŸ¥è¯¢åˆ—è¡¨ï¼Œæä¾›ä¸€ä¸ªç¾è§‚ä¸”ä¿¡æ¯ä¸°å¯Œçš„è¿›åº¦æ¡
    for query in tqdm(queries_to_run, desc="ğŸ” æ€»ä½“æœç´¢è¿›åº¦"):
        
        # åœ¨è¿›åº¦æ¡ä¸Šæ˜¾ç¤ºå½“å‰æ­£åœ¨æ‰§è¡Œçš„æŸ¥è¯¢
        tqdm.write(f"ğŸš€ å¼€å§‹æœç´¢: '{query}'")
        
        # ä¼ å…¥å†…å­˜ä¸­æ‰€æœ‰çš„keyï¼Œé¿å…é‡å¤æœç´¢å’Œè®°å½•
        newly_found_set = search_github(query, all_found_keys)
        
        if newly_found_set:
            count = len(newly_found_set)
            total_new_keys_this_run += count
            
            # âœ¨ æ ¸å¿ƒä¿®æ”¹ç‚¹: ä½¿ç”¨ 'a' (append) æ¨¡å¼æ¥è¿½åŠ æ–°å†…å®¹ âœ¨
            # è¿™æ ·æ—¢ä¸ä¼šè¦†ç›–æ—§æ•°æ®ï¼Œä¹Ÿèƒ½ä¿è¯ç¨‹åºä¸­æ–­æ—¶æ•°æ®ä¸ä¸¢å¤±ã€‚
            with open(OUTPUT_FILE, 'a', encoding='utf-8') as f:
                for key in newly_found_set:
                    f.write(f"{key}\n")
            
            # æ›´æ–°å†…å­˜ä¸­çš„é›†åˆï¼Œç¡®ä¿åç»­çš„æŸ¥è¯¢ä¸ä¼šæŠŠåˆšæ‰¾åˆ°çš„keyå½“ä½œæ–°çš„
            all_found_keys.update(newly_found_set)
            
            tqdm.write(f"  [âœ…] æŸ¥è¯¢ç»“æŸï¼Œå‘ç° {count} ä¸ªæ–°Keyã€‚å·²è¿½åŠ åˆ° {OUTPUT_FILE}ã€‚")
        else:
            # å¦‚æœæ²¡æœ‰æ–°å‘ç°ï¼Œé™é»˜å¤„ç†æˆ–åªåœ¨è¿›åº¦æ¡ä¸Šæ›´æ–°ï¼Œé¿å…åˆ·å±
            pass
            
    print("\n" + "="*50)
    print("âœ¨ å…¨éƒ¨æœç´¢ä»»åŠ¡å®Œæˆï¼")
    print(f"æœ¬æ¬¡è¿è¡Œå…±å‘ç° {total_new_keys_this_run} ä¸ªæ–°Keyã€‚")
    print(f"æ–‡ä»¶ä¸­æ€»è®¡ {len(all_found_keys)} æ¡ä¸é‡å¤è®°å½•ã€‚")
    print("="*50)


if __name__ == '__main__':
    # å»ºè®®åœ¨ä½¿ç”¨tqdmæ—¶ï¼Œå¦‚æœå¯èƒ½ï¼Œå®‰è£…coloramaåº“ä»¥è·å¾—æ›´å¥½çš„æ˜¾ç¤ºæ•ˆæœ
    # pip install colorama
    main()
